"""
ğŸ¯ SISTEMA DE APRENDIZADO CONTÃNUO COM RECOMPENSA/PUNIÃ‡ÃƒO
Executa busca automÃ¡tica a cada hora e aplica sistema de gamificaÃ§Ã£o

REGRAS:
âœ… Acerto (TP) = +100 pontos de recompensa + Aprende padrÃ£o vencedor
âŒ Erro  (SL) = -500 pontos (PUNIÃ‡ÃƒO SEVERA) + AnÃ¡lise do que deu errado
ğŸ¯ Meta: 5:1 ou mais (Risk/Reward)
ğŸ“š Notifica a cada aprendizado bem-sucedido
"""

import os
import sys
import json
import time
import schedule
from datetime import datetime

# Adicionar diretÃ³rio pai ao path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from ai.youtubeLearner import AdvancedCRTLearner

class RewardPunishmentLearner:
    def __init__(self):
        self.learner = AdvancedCRTLearner()
        self.rewards_file = 'rewards_punishments_log.json'
        self.rewards_data = self.load_rewards()
        
        # Sistema de pontuaÃ§Ã£o
        self.score = self.rewards_data.get('total_score', 0)
        self.wins = self.rewards_data.get('wins', 0)
        self.losses = self.rewards_data.get('losses', 0)
        self.learning_sessions = self.rewards_data.get('sessions', 0)
        
    def load_rewards(self):
        """Carrega dados de recompensas/puniÃ§Ãµes"""
        if os.path.exists(self.rewards_file):
            with open(self.rewards_file, 'r') as f:
                return json.load(f)
        return {
            'total_score': 0,
            'wins': 0,
            'losses': 0,
            'sessions': 0,
            'history': []
        }
    
    def save_rewards(self):
        """Salva dados de recompensas"""
        self.rewards_data['total_score'] = self.score
        self.rewards_data['wins'] = self.wins
        self.rewards_data['losses'] = self.losses
        self.rewards_data['sessions'] = self.learning_sessions
        
        with open(self.rewards_file, 'w') as f:
            json.dump(self.rewards_data, f, indent=2)
    
    def apply_reward(self, trade_result, profit=0):
        """Aplica recompensa ou puniÃ§Ã£o baseado no resultado do trade"""
        timestamp = datetime.now().isoformat()
        
        if trade_result == 'WIN':
            # âœ… RECOMPENSA POR ACERTO
            reward_points = 100
            self.score += reward_points
            self.wins += 1
            
            log_entry = {
                'timestamp': timestamp,
                'result': 'WIN',
                'points': reward_points,
                'profit': profit,
                'total_score': self.score,
                'message': f'âœ… ACERTO! +{reward_points} pontos | Lucro: ${profit:.2f}'
            }
            
            # NotificaÃ§Ã£o de sucesso
            self.notify_achievement(profit, reward_points)
            
        elif trade_result == 'LOSS':
            # âŒ PUNIÃ‡ÃƒO SEVERA POR ERRO
            punishment_points = -500
            self.score += punishment_points
            self.losses += 1
            
            log_entry = {
                'timestamp': timestamp,
                'result': 'LOSS',
                'points': punishment_points,
                'profit': profit,
                'total_score': self.score,
                'message': f'âŒ ERRO! {punishment_points} pontos (PUNIÃ‡ÃƒO SEVERA) | Perda: ${profit:.2f}'
            }
            
            # Aprender com o erro
            print(f"\n{'='*70}")
            print(f"âš ï¸ PUNIÃ‡ÃƒO APLICADA: {punishment_points} pontos")
            print(f"ğŸ“‰ Score total: {self.score}")
            print(f"ğŸ” Analisando o que deu errado...")
            print(f"{'='*70}\n")
        
        # Adicionar ao histÃ³rico
        self.rewards_data['history'].append(log_entry)
        
        # Manter apenas Ãºltimos 100 registros
        if len(self.rewards_data['history']) > 100:
            self.rewards_data['history'] = self.rewards_data['history'][-100:]
        
        self.save_rewards()
        
        return log_entry
    
    def notify_achievement(self, profit, points):
        """Notifica quando a IA alcanÃ§a meta de lucro"""
        print(f"\n{'='*70}")
        print(f"ğŸ¯ ALVO ALCANÃ‡ADO!")
        print(f"ğŸ’° Meta de lucro buscada: 5:1 ou mais")
        print(f"ğŸ’µ Valor alcanÃ§ado nesta operaÃ§Ã£o: ${profit:.2f}")
        print(f"â­ Pontos de recompensa: +{points}")
        print(f"ğŸ“Š Score total: {self.score}")
        print(f"âœ… Wins: {self.wins} | âŒ Losses: {self.losses}")
        print(f"ğŸ“ˆ Win Rate: {(self.wins/(self.wins+self.losses)*100) if (self.wins+self.losses) > 0 else 0:.1f}%")
        print(f"{'='*70}\n")
    
    def hourly_learning(self):
        """ExecuÃ§Ã£o de hora em hora - Busca e aprende"""
        self.learning_sessions += 1
        
        print(f"\n{'ğŸ”¥'*35}")
        print(f"ğŸ§  SESSÃƒO DE APRENDIZADO #{self.learning_sessions}")
        print(f"â° {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
        print(f"{'ğŸ”¥'*35}\n")
        
        # Realizar aprendizado do YouTube
        print("ğŸ“º Buscando novos vÃ­deos no YouTube...")
        try:
            result = self.learner.update_knowledge(focus_novo_legacy=True)
            
            if result:
                new_videos = result.get('new_videos', 0)
                new_concepts = result.get('new_concepts', 0)
                
                print(f"\nâœ… Aprendizado concluÃ­do!")
                print(f"ğŸ“¹ Novos vÃ­deos analisados: {new_videos}")
                print(f"ğŸ’¡ Novos conceitos aprendidos: {new_concepts}")
                print(f"ğŸ“Š Score atual: {self.score}")
                
                # Salvar progresso
                self.save_rewards()
                
        except Exception as e:
            print(f"âŒ Erro durante aprendizado: {str(e)}")
        
        print(f"\nâ³ PrÃ³xima sessÃ£o em 1 hora...\n")
    
    def start_continuous_learning(self):
        """Inicia aprendizado contÃ­nuo de hora em hora"""
        print(f"\n{'='*70}")
        print(f"ğŸš€ SISTEMA DE APRENDIZADO CONTÃNUO INICIADO")
        print(f"â° Busca automÃ¡tica: A CADA HORA")
        print(f"ğŸ¯ Objetivo: Maximizar lucro 5:1 ou mais")
        print(f"âœ… Recompensa por acerto: +100 pontos")
        print(f"âŒ PuniÃ§Ã£o por erro: -500 pontos (SEVERA)")
        print(f"{'='*70}\n")
        
        # Executar imediatamente na inicializaÃ§Ã£o
        self.hourly_learning()
        
        # Agendar execuÃ§Ãµes de hora em hora
        schedule.every(1).hours.do(self.hourly_learning)
        
        # Loop infinito
        print("ğŸ”„ Sistema rodando... (Ctrl+C para parar)")
        try:
            while True:
                schedule.run_pending()
                time.sleep(60)  # Verificar a cada minuto
        except KeyboardInterrupt:
            print("\n\nâ¹ï¸  Sistema de aprendizado parado.")
            print(f"ğŸ“Š Stats Finais:")
            print(f"   Score: {self.score}")
            print(f"   Wins: {self.wins}")
            print(f"   Losses: {self.losses}")
            print(f"   SessÃµes: {self.learning_sessions}")


if __name__ == "__main__":
    learner = RewardPunishmentLearner()
    learner.start_continuous_learning()
